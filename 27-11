import numpy as np
import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import SimpleRNN, Dense, Dropout
from tensorflow.keras.utils import to_categorical
from PIL import Image
import requests
from io import BytesIO
import matplotlib.pyplot as plt
from google.colab import files  # For uploading images in Google Colab

# Load the MNIST dataset
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Preprocess the data (normalize and reshape for RNN)
x_train = x_train / 255.0  # Normalize pixel values to [0, 1]
x_test = x_test / 255.0

# One-hot encode the labels
y_train = to_categorical(y_train, num_classes=10)
y_test = to_categorical(y_test, num_classes=10)

# RNN requires 3D input shape (samples, timesteps, features)
# We already have (28, 28) for MNIST, which is (timesteps, features)
timesteps = x_train.shape[1]
input_dim = x_train.shape[2]

# Build the RNN model
model = Sequential([
    SimpleRNN(128, input_shape=(timesteps, input_dim), activation='relu', return_sequences=True),
    Dropout(0.2),
    SimpleRNN(64, activation='relu'),
    Dropout(0.2),
    Dense(64, activation='relu'),
    Dense(10, activation='softmax')  # Output layer for 10 classes (digits 0-9)
])

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)

# Evaluate the model on test data
test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)
print(f"Test Accuracy: {test_accuracy:.2f}")

# Function to process and predict an uploaded image
def predict_handwritten_image():
    # Upload the image
    uploaded = files.upload()  # Upload the file
    image_path = next(iter(uploaded))  # Get the uploaded file name
    
    # Open the uploaded image
    img = Image.open(image_path) 
    
    # Preprocess the image: convert to grayscale, resize to 28x28, and normalize
    img = img.convert('L')  # Convert to grayscale
    img = img.resize((28, 28))  # Resize to 28x28
    img_array = np.array(img) / 255.0  # Normalize the pixel values
    
    # Reshape the image to match the model input shape (1, 28, 28)
    img_array = img_array.reshape(1, 28, 28)
    
    # Predict the class of the image
    prediction = model.predict(img_array)
    predicted_class = np.argmax(prediction)
    
    # Display the image and prediction
    plt.imshow(img, cmap='gray')
    plt.title(f"Predicted Class: {predicted_class}")
    plt.show()
    
    return predicted_class, img_array

# Continuous loop for new image predictions and fine-tuning
while True:
    # Predict and display the result for the uploaded image
    predicted_class, img_array = predict_handwritten_image()

    print(f"Predicted digit: {predicted_class}")
    
    # Ask the user for the correct label if the prediction is wrong
    correct_label = int(input("Enter the correct label for this image (or type 'q' to quit): "))
    
    # Exit the loop if the user chooses to quit
    if correct_label == 'q':
        print("Exiting the program.")
        break
    
    # Convert the correct label to one-hot encoding
    correct_label_onehot = to_categorical([correct_label], num_classes=10)

    # Retrain the model with this new image and its label (fine-tuning)
    model.fit(img_array, correct_label_onehot, epochs=1, batch_size=1)

    # Re-evaluate the model after fine-tuning
    test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)
    print(f"Test Accuracy after fine-tuning: {test_accuracy:.2f}")
