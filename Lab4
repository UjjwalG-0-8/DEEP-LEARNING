import torch
import torchvision
from torchvision.transforms import functional as F
import cv2
import numpy as np
from google.colab.patches import cv2_imshow
from google.colab import files
from collections import Counter

# Load the pre-trained Faster R-CNN model
model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)
model.eval()

# Define COCO object categories
COCO_INSTANCE_CATEGORY_NAMES = [
    '__background__', 'person', 'bicycle', 'car', 'motorcycle',
    'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench',
    'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella',
    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',
    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana',
    'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant',
    'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 
    'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'
]

# Function to upload an image
def upload_image():
    uploaded = files.upload()
    for fn in uploaded.keys():
        return fn

# Function to perform object detection
def detect_objects(image_path):
    img = cv2.imread(image_path)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img_tensor = F.to_tensor(img_rgb).unsqueeze(0)
    
    with torch.no_grad():
        predictions = model(img_tensor)
    
    filtered_predictions = []
    for i in range(len(predictions[0]['boxes'])):
        label_index = int(predictions[0]['labels'][i])
        # Ensure the label index is within the valid range
        label_index = min(label_index, len(COCO_INSTANCE_CATEGORY_NAMES) - 1)
        if predictions[0]['scores'][i] >= 0.5: # Threshold for confidence score
            filtered_predictions.append({
                'box': predictions[0]['boxes'][i].tolist(),
                'label': COCO_INSTANCE_CATEGORY_NAMES[label_index],
                'score': predictions[0]['scores'][i].item()
            })
    
    return filtered_predictions

# Function to display object count
def display_object_count(detections):
    labels = [detection['label'] for detection in detections]
    label_counts = Counter(labels)
    
    for label, count in label_counts.items():
        print(f"{label}: {count} instance(s)")

# Upload image
image_path = upload_image()

# Perform object detection
detections = detect_objects(image_path)

# Display results
img = cv2.imread(image_path)

# Draw bounding boxes and labels
for detection in detections:
    print(f"Detected {detection['label']} with confidence {detection['score']:.2f} at {detection['box']}")
    x1, y1, x2, y2 = map(int, detection['box'])
    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
    cv2.putText(img, detection['label'], (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)

# Display object count
display_object_count(detections)

# Show the image with bounding boxes
cv2_imshow(img)
